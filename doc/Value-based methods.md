Techniques for solving MDPs (and POMDPs) can be separated into three categories:
1. **Value-based** techniques aim to learn the value of states (or learn an estimate for value of states) and actions, i.e. learn value function or Q function.  Using policy extraction to get a policy for deciding actions.
2. **Policy-based** techniques learn a policy directly, which complete by-passes learning values of states or action together. It is important in case the state space or the action space are massive or infinite.
3. **Hybrid** techniques that combine value- and policy-based techniques.

| Previous                      |                Next |
| :---------------------------- | ------------------: |
| [[Markov Decision Processes]] | [[Value Iteration]] |
